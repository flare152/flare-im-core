//! Wire é£æ ¼çš„ä¾èµ–æ³¨å…¥æ¨¡å—
//!
//! ç±»ä¼¼ Go çš„ Wire æ¡†æ¶ï¼Œæä¾›ç®€å•çš„ä¾èµ–æ„å»ºæ–¹æ³•

use std::sync::Arc;

use anyhow::{Context, Result};
use flare_proto::storage::storage_reader_service_client::StorageReaderServiceClient;
use flare_server_core::kafka::build_kafka_producer;

use crate::application::handlers::MessageCommandHandler;
use crate::config::MessageOrchestratorConfig;
use crate::domain::repository::{
    MessageEventPublisherItem, ConversationRepositoryItem, WalRepositoryItem,
};
use crate::domain::service::{MessageDomainService, MessageTemporaryService, SequenceAllocator};
use crate::infrastructure::external::session_client::GrpcConversationClient;
use crate::infrastructure::messaging::kafka_publisher::KafkaMessagePublisher;
use crate::infrastructure::persistence::noop_wal::NoopWalRepository;
use crate::infrastructure::persistence::redis_wal::RedisWalRepository;
use crate::interface::grpc::handler::MessageGrpcHandler;
use flare_im_core::hooks::adapters::DefaultHookFactory;
use flare_im_core::hooks::{HookConfigLoader, HookDispatcher, HookRegistry};
use flare_im_core::metrics::MessageOrchestratorMetrics;
use flare_proto::conversation::conversation_service_client::ConversationServiceClient;

/// åº”ç”¨ä¸Šä¸‹æ–‡ - åŒ…å«æ‰€æœ‰å·²åˆå§‹åŒ–çš„æœåŠ¡
pub struct ApplicationContext {
    pub handler: MessageGrpcHandler,
    pub config: Arc<MessageOrchestratorConfig>,
}

/// æ„å»ºåº”ç”¨ä¸Šä¸‹æ–‡
///
/// ç±»ä¼¼ Go Wire çš„ Initialize å‡½æ•°ï¼ŒæŒ‰ç…§ä¾èµ–é¡ºåºæ„å»ºæ‰€æœ‰ç»„ä»¶
///
/// # å‚æ•°
/// * `app_config` - åº”ç”¨é…ç½®
///
/// # è¿”å›
/// * `ApplicationContext` - æ„å»ºå¥½çš„åº”ç”¨ä¸Šä¸‹æ–‡
pub async fn initialize(
    app_config: &flare_im_core::config::FlareAppConfig,
) -> Result<ApplicationContext> {
    // 1. åŠ è½½é…ç½®
    let config = Arc::new(MessageOrchestratorConfig::from_app_config(app_config));

    // 2. åˆ›å»º Kafka Producerï¼ˆä½¿ç”¨ç»Ÿä¸€çš„æ„å»ºå™¨ï¼‰
    let producer =
        build_kafka_producer(config.as_ref() as &dyn flare_server_core::kafka::KafkaProducerConfig)
            .context("Failed to create Kafka producer")?;

    // 3. æ„å»ºæ¶ˆæ¯å‘å¸ƒå™¨ï¼ˆnew æ–¹æ³•è¿”å› Arc<Self>ï¼ŒåŒ…è£…ä¸º enumï¼‰
    let kafka_publisher = KafkaMessagePublisher::new(Arc::new(producer), config.clone());
    let publisher = Arc::new(MessageEventPublisherItem::Kafka(kafka_publisher));

    // 4. æ„å»º WAL Repository
    let wal_repository =
        build_wal_repository(&config).context("Failed to create WAL repository")?;

    // 5. æ„å»º Hook Dispatcher
    let hooks = build_hook_dispatcher(&config)
        .await
        .context("Failed to create Hook dispatcher")?;

    // 6. ğŸ”¹ æ„å»º SequenceAllocatorï¼ˆæ ¸å¿ƒèƒ½åŠ›ï¼šä¿è¯æ¶ˆæ¯é¡ºåºï¼‰
    let sequence_allocator = build_sequence_allocator(&config)
        .await
        .context("Failed to create SequenceAllocator")?;

    // 7. åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†
    let metrics = Arc::new(MessageOrchestratorMetrics::new());

    // 8. æ„å»º Session æœåŠ¡å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
    let conversation_repository = build_conversation_client(&config).await;

    // 9. æ„å»ºé¢†åŸŸæœåŠ¡
    let domain_service = Arc::new(MessageDomainService::new(
        Arc::clone(&publisher), // ä½¿ç”¨ Arc::clone é¿å…ç§»åŠ¨
        wal_repository.clone(), // å…ˆ cloneï¼Œåç»­è¿˜éœ€è¦ä½¿ç”¨
        conversation_repository,
        sequence_allocator,
        config.defaults(),
        hooks,
    ));

    // 10. æ„å»º Storage Reader å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº† reader_endpointï¼‰
    let reader_client = build_storage_reader_client(&config).await;

    // 11. æ„å»ºæŸ¥è¯¢å¤„ç†å™¨
    let query_handler = Arc::new(crate::application::handlers::MessageQueryHandler::new(
        domain_service.clone(),
        reader_client.clone().map(|client| Arc::new(client)),
    ));

    // 12. æ„å»ºæ¶ˆæ¯æ“ä½œæœåŠ¡ï¼ˆæ€»æ˜¯åˆ›å»ºï¼Œå¦‚æœæ²¡æœ‰ reader_client åˆ™ä½¿ç”¨ Noop MessageRepositoryï¼‰
    use crate::domain::service::message_operation_service::{MessageOperationService, EventPublisher, MessageRepository};
    use crate::domain::model::Message;
    
    let message_repo: Arc<dyn MessageRepository> = if let Some(ref reader_client) = reader_client {
        use crate::infrastructure::persistence::message_repository_adapter::StorageReaderMessageRepository;
        Arc::new(StorageReaderMessageRepository::new(Arc::new(reader_client.clone())))
    } else {
        // åˆ›å»º Noop MessageRepositoryï¼ˆå½“ reader_client ä¸å­˜åœ¨æ—¶ï¼‰
        struct NoopMessageRepository;
        #[async_trait::async_trait]
        impl MessageRepository for NoopMessageRepository {
            async fn find_by_id(&self, _message_id: &str) -> Result<Option<Message>> {
                Ok(None) // æ€»æ˜¯è¿”å› Noneï¼Œè¡¨ç¤ºæ¶ˆæ¯ä¸å­˜åœ¨
            }
            async fn save(&self, _message: &Message) -> Result<()> {
                Ok(()) // Noopï¼Œä¸ä¿å­˜
            }
        }
        Arc::new(NoopMessageRepository)
    };
    
    struct NoopEventPublisher;
    #[async_trait::async_trait]
    impl EventPublisher for NoopEventPublisher {
        async fn publish_recalled(&self, _: &crate::domain::event::MessageRecalledEvent) -> Result<()> { Ok(()) }
        async fn publish_edited(&self, _: &crate::domain::event::MessageEditedEvent) -> Result<()> { Ok(()) }
        async fn publish_deleted(&self, _: &crate::domain::event::MessageDeletedEvent) -> Result<()> { Ok(()) }
        async fn publish_read(&self, _: &crate::domain::event::MessageReadEvent) -> Result<()> { Ok(()) }
        async fn publish_reaction_added(&self, _: &crate::domain::event::MessageReactionAddedEvent) -> Result<()> { Ok(()) }
        async fn publish_reaction_removed(&self, _: &crate::domain::event::MessageReactionRemovedEvent) -> Result<()> { Ok(()) }
        async fn publish_pinned(&self, _: &crate::domain::event::MessagePinnedEvent) -> Result<()> { Ok(()) }
        async fn publish_unpinned(&self, _: &crate::domain::event::MessageUnpinnedEvent) -> Result<()> { Ok(()) }
        async fn publish_favorited(&self, _: &crate::domain::event::MessageFavoritedEvent) -> Result<()> { Ok(()) }
        async fn publish_unfavorited(&self, _: &crate::domain::event::MessageUnfavoritedEvent) -> Result<()> { Ok(()) }
    }
    
    let operation_service = Arc::new(MessageOperationService::new(
        message_repo,
        Arc::new(NoopEventPublisher),
        publisher.clone(),
        Some(wal_repository.clone()), // æ³¨å…¥ WAL Repository ç”¨äº fallback æŸ¥è¯¢
    ));

    // 13. æ„å»ºä¸´æ—¶æ¶ˆæ¯å¤„ç†æœåŠ¡
    let temporary_service = Arc::new(MessageTemporaryService::new(publisher.clone()));

    // 14. æ„å»ºå‘½ä»¤å¤„ç†å™¨
    let command_handler = Arc::new(MessageCommandHandler::new(
        domain_service,
        operation_service.clone(),
        Some(temporary_service.clone()),
        metrics,
    ));

    // 15. æ„å»º gRPC å¤„ç†å™¨ï¼ˆåªä¾èµ– command_handler å’Œ query_handlerï¼‰
    let handler = MessageGrpcHandler::new(
        command_handler,
        query_handler,
    );

    Ok(ApplicationContext {
        handler,
        config,
    })
}

// build_kafka_producer å‡½æ•°å·²ç§»é™¤ï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨ flare_server_core::kafka::build_kafka_producer

/// æ„å»º WAL Repository
fn build_wal_repository(config: &Arc<MessageOrchestratorConfig>) -> Result<Arc<WalRepositoryItem>> {
    if let Some(url) = &config.redis_url {
        let client =
            Arc::new(redis::Client::open(url.as_str()).context("Failed to create Redis client")?);
        Ok(Arc::new(WalRepositoryItem::Redis(Arc::new(
            RedisWalRepository::new(client, config.clone()),
        ))))
    } else {
        Ok(Arc::new(WalRepositoryItem::Noop(Arc::new(
            NoopWalRepository::default(),
        ))))
    }
}

/// æ„å»º SequenceAllocatorï¼ˆæ ¸å¿ƒèƒ½åŠ›ï¼šä¿è¯æ¶ˆæ¯é¡ºåºï¼‰
///
/// # è®¾è®¡åŸç†
///
/// 1. ä¼˜å…ˆä½¿ç”¨ Redis å®ç°ï¼ˆé«˜æ€§èƒ½ã€å¼ºä¸€è‡´ï¼‰
/// 2. å¦‚æœæœªé…ç½® Redisï¼Œé™çº§åˆ°æ—¶é—´æˆ³æ¨¡å¼ï¼ˆæ€§èƒ½æ›´é«˜ï¼Œä½†ä¸ä¿è¯ä¸¥æ ¼é¡ºåºï¼‰
/// 3. é¢„åˆ†é…æ‰¹æ¬¡å¤§å°ä»é…ç½®è¯»å–ï¼ˆé»˜è®¤ 100ï¼‰
async fn build_sequence_allocator(
    config: &Arc<MessageOrchestratorConfig>,
) -> Result<Arc<SequenceAllocator>> {
    if let Some(url) = &config.redis_url {
        // Redis æ¨¡å¼ï¼ˆæ¨èï¼‰ï¼šå¼ºä¸€è‡´æ€§åºåˆ—å·
        let client = Arc::new(
            redis::Client::open(url.as_str())
                .context("Failed to create Redis client for SequenceAllocator")?,
        );

        // æ‰¹æ¬¡å¤§å°å¯ä»¥ä»é…ç½®è¯»å–ï¼ˆè¿™é‡Œé»˜è®¤ 100ï¼‰
        let batch_size = 100;

        tracing::info!(
            redis_url = %url,
            batch_size = batch_size,
            "SequenceAllocator initialized with Redis backend"
        );

        Ok(Arc::new(SequenceAllocator::new(client, batch_size).await?))
    } else {
        // é™çº§æ¨¡å¼ï¼šä½¿ç”¨è™šæ‹Ÿ Redis å®¢æˆ·ç«¯ï¼ˆæ‰€æœ‰æ“ä½œéƒ½è¿”å›é”™è¯¯ï¼Œè§¦å‘é™çº§åˆ°æ—¶é—´æˆ³æ¨¡å¼ï¼‰
        // è¿™æ ·å¯ä»¥ä¿æŒç»Ÿä¸€çš„æ¥å£ï¼Œä¸éœ€è¦ç‰¹æ®Šå¤„ç†
        tracing::warn!(
            "Redis not configured, SequenceAllocator will use degraded mode (timestamp-based). \
             This does NOT guarantee strict message ordering!"
        );

        // åˆ›å»ºä¸€ä¸ªå‡çš„ Redis å®¢æˆ·ç«¯ï¼ˆè¿æ¥åˆ°æ— æ•ˆåœ°å€ï¼Œç¡®ä¿æ‰€æœ‰æ“ä½œå¤±è´¥ï¼‰
        let fake_client = Arc::new(
            redis::Client::open("redis://127.0.0.1:0")
                .context("Failed to create fake Redis client")?,
        );

        Ok(Arc::new(SequenceAllocator::new(fake_client, 100).await?))
    }
}

/// æ„å»º Hook Dispatcher
async fn build_hook_dispatcher(
    config: &Arc<MessageOrchestratorConfig>,
) -> Result<Arc<HookDispatcher>> {
    let mut hook_loader = HookConfigLoader::new();
    if let Some(path) = &config.hook_config {
        hook_loader = hook_loader.add_candidate(path.clone());
    }
    if let Some(dir) = &config.hook_config_dir {
        hook_loader = hook_loader.add_candidate(dir.clone());
    }
    let hook_config = hook_loader
        .load()
        .map_err(|err| anyhow::anyhow!("Failed to load hook config: {}", err))?;
    let registry = HookRegistry::builder().build();
    let hook_factory = DefaultHookFactory::new()
        .map_err(|err| anyhow::anyhow!("Failed to create hook factory: {}", err))?;
    hook_config
        .install(Arc::clone(&registry), &hook_factory)
        .await
        .map_err(|err| anyhow::anyhow!("Failed to install hooks: {}", err))?;
    Ok(Arc::new(HookDispatcher::new(registry)))
}

/// æ„å»º Session æœåŠ¡å®¢æˆ·ç«¯
async fn build_conversation_client(
    config: &Arc<MessageOrchestratorConfig>,
) -> Option<Arc<ConversationRepositoryItem>> {
    // ä½¿ç”¨æœåŠ¡å‘ç°åˆ›å»º session æœåŠ¡å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å¸¸é‡ï¼Œæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
    use flare_im_core::service_names::{CONVERSATION, get_service_name};
    let conversation_service = config
        .conversation_service_type
        .as_deref()
        .map(|s| s.to_string())
        .unwrap_or_else(|| get_service_name(CONVERSATION));

    // æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…æœåŠ¡å‘ç°é˜»å¡æ•´ä¸ªå¯åŠ¨è¿‡ç¨‹
    let discover_result = tokio::time::timeout(
        std::time::Duration::from_secs(3),
        flare_im_core::discovery::create_discover(&conversation_service),
    )
    .await;

    match discover_result {
        Ok(Ok(Some(discover))) => {
            let mut service_client = flare_server_core::discovery::ServiceClient::new(discover);
            // æ·»åŠ è¶…æ—¶ä¿æŠ¤è·å– channel
            match tokio::time::timeout(
                std::time::Duration::from_secs(3),
                service_client.get_channel(),
            )
            .await
            {
                Ok(Ok(channel)) => {
                    tracing::info!(service = %conversation_service, "Connected to Session service via service discovery");
                    Some(Arc::new(ConversationRepositoryItem::Grpc(Arc::new(
                        GrpcConversationClient::new(ConversationServiceClient::new(channel)),
                    ))))
                }
                Ok(Err(err)) => {
                    tracing::warn!(error = %err, service = %conversation_service, "Failed to get Session service channel, session auto-creation disabled");
                    None
                }
                Err(_) => {
                    tracing::warn!(service = %conversation_service, "Timeout getting Session service channel after 3s, session auto-creation disabled");
                    None
                }
            }
        }
        Ok(Ok(None)) => {
            tracing::debug!(service = %conversation_service, "Session service discovery not configured, session auto-creation disabled");
            None
        }
        Ok(Err(err)) => {
            tracing::warn!(error = %err, service = %conversation_service, "Failed to create Session service discover, session auto-creation disabled");
            None
        }
        Err(_) => {
            tracing::warn!(service = %conversation_service, "Timeout creating Session service discover after 3s, session auto-creation disabled");
            None
        }
    }
}

/// æ„å»º Storage Reader å®¢æˆ·ç«¯
async fn build_storage_reader_client(
    config: &Arc<MessageOrchestratorConfig>,
) -> Option<StorageReaderServiceClient<tonic::transport::Channel>> {
    if let Some(endpoint) = &config.reader_endpoint {
        match tonic::transport::Endpoint::from_shared(endpoint.clone()) {
            Ok(endpoint) => match StorageReaderServiceClient::connect(endpoint.clone()).await {
                Ok(client) => {
                    tracing::info!(endpoint = %endpoint.uri(), "Connected to Storage Reader");
                    Some(client)
                }
                Err(err) => {
                    tracing::error!(error = ?err, endpoint = %endpoint.uri(), "Failed to connect to Storage Reader");
                    None
                }
            },
            Err(err) => {
                tracing::error!(error = ?err, endpoint = %endpoint, "Invalid Storage Reader endpoint");
                None
            }
        }
    } else {
        None
    }
}
